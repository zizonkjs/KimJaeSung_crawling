'''
ì´ ì½”ë“œëŠ” Seleniumê³¼ BeautifulSoupì„ ì´ìš©í•˜ì—¬ ì‚¬ëŒì¸(saramin.co.kr)ì—ì„œ "AI ê´€ë ¨ ì±„ìš© ê³µê³ " ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³ , CSV íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ìë™í™” ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.

ğŸ“Œ ì£¼ìš” ë™ì‘ ê³¼ì •
ì›¹ë“œë¼ì´ë²„ ì‹¤í–‰

webdriver.Chrome()ì„ ì‹¤í–‰í•˜ì—¬ í¬ë¡¬ ë¸Œë¼ìš°ì €ë¥¼ ì—½ë‹ˆë‹¤.
ì‚¬ëŒì¸ AI ì±„ìš© ê³µê³  í˜ì´ì§€ ì´ë™

driver.get(url)ì„ í†µí•´ í•´ë‹¹ URLì˜ í˜ì´ì§€ë¡œ ì´ë™í•œ í›„, time.sleep(5)ë¡œ í˜ì´ì§€ê°€ ì™„ì „íˆ ë¡œë”©ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
HTML í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸° ë° íŒŒì‹±

driver.page_sourceë¡œ í˜ì´ì§€ HTMLì„ ê°€ì ¸ì˜¨ í›„, BeautifulSoupì„ ì‚¬ìš©í•˜ì—¬ HTMLì„ íŒŒì‹±í•©ë‹ˆë‹¤.
CSV íŒŒì¼ ìƒì„± ë° í—¤ë” ì‘ì„±

'saramin_jobs.csv3' íŒŒì¼ì„ ìƒì„±í•˜ê³ , **í—¤ë”(íšŒì‚¬ì´ë¦„, ì±„ìš©ì •ë³´, ì±„ìš©ì¡°ê±´, Job Sector)**ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
ì±„ìš© ê³µê³  ë°ì´í„° í¬ë¡¤ë§

soup.find('div', class_='list_body')ì—ì„œ ê³µê³  ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ê³ ,
ê° div.box_item ìš”ì†Œì—ì„œ
íšŒì‚¬ ì´ë¦„ (company_nm)
ì±„ìš© ì •ë³´ (job_tit)
ì±„ìš© ì¡°ê±´ (recruit_info)
ì§ë¬´ ë¶„ì•¼ (job_sector)
ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
CSV íŒŒì¼ ì €ì¥

ì¶”ì¶œí•œ ë°ì´í„°ë¥¼ CSV íŒŒì¼ì— í•œ ì¤„ì”© ì €ì¥í•©ë‹ˆë‹¤.
ë¸Œë¼ìš°ì € ì¢…ë£Œ

driver.quit()ì„ í˜¸ì¶œí•˜ì—¬ í¬ë¡¤ë§ì´ ëë‚˜ë©´ í¬ë¡¬ ë¸Œë¼ìš°ì €ë¥¼ ë‹«ìŠµë‹ˆë‹¤.
'''
from selenium import webdriver
from bs4 import BeautifulSoup
import collections
import time

if not hasattr(collections, 'Callable'):
    collections.Callable = collections.abc.Callable
import csv
import time
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By

# ì›¹ë“œë¼ì´ë²„ ì„¤ì •
driver = webdriver.Chrome()

# ì‚¬ë¼ë¯¼ í˜ì´ì§€ë¡œ ì´ë™
url = 'https://www.saramin.co.kr/zf_user/jobs/list/job-category?page=1&cat_mcls=2&loc_mcd=104000&searchword=AI&searchType=recently&search_optional_item=y&search_done=y&panel_count=y&preview=y&isAjaxRequest=0&page_count=100&sort=RL&type=job-category&is_param=1&isSearchResultEmpty=1&isSectionHome=0&searchParamCount=3&tab=job-category'
driver.get(url)
time.sleep(5)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°

# í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°
html = driver.page_source
soup = BeautifulSoup(html, 'html.parser')

# CSV íŒŒì¼ ìƒì„± ë° í—¤ë” ì‘ì„±
with open('saramin_jobs.csv3', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(['íšŒì‚¬ì´ë¦„', 'ì±„ìš©ì •ë³´', 'ì±„ìš©ì¡°ê±´', 'Job Sector'])

    # ê° ì±„ìš©ê³µê³  í¬ë¡¤ë§
    job_items = soup.find('div', class_='list_body').find_all('div', class_='box_item')

    for item in job_items:
        company_name = item.find('div', class_='company_nm').get_text(strip=True)
        job_info = item.find('div', class_='job_tit').get_text(strip=True)
        job_condition = item.find('div', class_='recruit_info').get_text(strip=True)
        
        job_sector_tags = item.find('span', class_='job_sector').find_all('span')
        job_sector = ', '.join([tag.get_text(strip=True) for tag in job_sector_tags])

        writer.writerow([company_name, job_info, job_condition, job_sector])

# ë¸Œë¼ìš°ì € ì¢…ë£Œ
driver.quit()
